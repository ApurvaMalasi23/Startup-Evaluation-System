{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMGufijG8DoJn6VzOHkfE9U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yfVJQgoJSbtA"},"outputs":[],"source":["!pip install -q transformers datasets scikit-learn"]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification, get_scheduler\n","from transformers import AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","from tqdm import tqdm"],"metadata":{"id":"865VepnwTgo0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sample financial text dataset\n","data = {\n","    'text': [\n","        \"The company posted a net profit of 10 million dollars.\",\n","        \"Revenue declined by 15% in the last quarter.\",\n","        \"There was a significant increase in operational costs.\",\n","        \"Positive growth forecast for next year.\",\n","        \"Stock prices are expected to rise after merger announcement.\"\n","    ],\n","    'label': ['positive', 'negative', 'negative', 'positive', 'positive']\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","df['label_enc'] = label_encoder.fit_transform(df['label'])\n","\n","# Split data\n","train_texts, val_texts, train_labels, val_labels = train_test_split(\n","    df['text'].tolist(), df['label_enc'].tolist(), test_size=0.2, random_state=42\n",")"],"metadata":{"id":"AqEUpo4uTjjM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","class FinancialDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len=128):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        encoding = self.tokenizer(\n","            self.texts[idx],\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=self.max_len,\n","            return_tensors=\"pt\"\n","        )\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(),\n","            'attention_mask': encoding['attention_mask'].squeeze(),\n","            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n","        }\n","\n","train_dataset = FinancialDataset(train_texts, train_labels, tokenizer)\n","val_dataset = FinancialDataset(val_texts, val_labels, tokenizer)\n","\n","train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=2)"],"metadata":{"id":"aIoPMSF0TnLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","model.to(device)"],"metadata":{"id":"RKsJSzOtTr_g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","num_training_steps = len(train_loader) * 3  # 3 epochs\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps,\n",")"],"metadata":{"id":"byUl2BEGTvjS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train()\n","\n","for epoch in range(3):  # 3 epochs\n","    total_loss = 0\n","    for batch in tqdm(train_loader):\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = model(**batch)\n","        loss = outputs.loss\n","        loss.backward()\n","        total_loss += loss.item()\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","\n","    print(f\"Epoch {epoch + 1} Loss: {total_loss / len(train_loader)}\")"],"metadata":{"id":"TVL7UgRCT2X_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for batch in val_loader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        outputs = model(**batch)\n","        predictions = torch.argmax(outputs.logits, dim=-1)\n","        correct += (predictions == batch['labels']).sum().item()\n","        total += batch['labels'].size(0)\n","\n","print(f\"Validation Accuracy: {correct / total * 100:.2f}%\")"],"metadata":{"id":"MNvYJOGDT8ZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def classify_text(text):\n","    model.eval()\n","    encoding = tokenizer(\n","        text,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        padding=\"max_length\",\n","        max_length=128\n","    )\n","    encoding = {k: v.to(device) for k, v in encoding.items()}\n","    with torch.no_grad():\n","        outputs = model(**encoding)\n","        prediction = torch.argmax(outputs.logits, dim=-1).item()\n","    return label_encoder.inverse_transform([prediction])[0]\n","\n","# Example usage:\n","print(classify_text(\"The company showed a strong increase in sales this quarter.\"))"],"metadata":{"id":"kUZnj9l3T9z4"},"execution_count":null,"outputs":[]}]}